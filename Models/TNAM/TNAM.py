# -*- coding: utf-8 -*-
"""TNAM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-xn9sJXeLn0PlC9VKuIjjr2QWB4PyFrL

## Importing data
"""

# This code installs the yfinance library, which allows you to access financial data from Yahoo Finance
!pip install yfinance

# Import the yfinance library and assign it to the alias 'yf'
import yfinance as yf

# Create a list of tickers for the stocks you want to retrieve data for
list_tickers = ['CL=F','^GSPC', '^TNX', 'XOM']

# Use the Tickers() function from yfinance to create an object for each ticker in the list
tickers = yf.Tickers(list_tickers)

# Use the download() function from yfinance to download the stock data for the specified date range
data = yf.download(list_tickers,  start="2007-06-01", end="2022-07-01")

# Extract the 'Close' column from the dataframe
data = data['Close']

# Print the dataframe
data

# Remove all rows with missing values (NaN) from the dataframe
data = data.dropna()

# Check if the dataframe still contains any missing values
# returns False if there is no missing values
data.isnull().values.any()

"""##Statistical analysis """

## Compute the Pearson's correlation coefficient between the columns
corr_matrix = data.corr()
print(corr_matrix)

## The spearmanr function returns two values: the Spearman's rank correlation coefficient (corr) and the p-value. The p-value can be used 
## to assess the statistical significance of the correlation. A small p-value (typically less than 0.05) 
## indicates that the correlation is statistically significant, while a large p-value suggests that the correlation may not be meaningful.

from scipy.stats import spearmanr

# Compute the Spearman's rank correlation matrix
corr_matrix = data.corr(method='spearman')

# Extract the column names
column_names = data.columns

# Loop through all pairs of variables
for i in range(len(column_names)):
    for j in range(i+1, len(column_names)):
        # Extract the columns of interest
        x = data[column_names[i]].values
        y = data[column_names[j]].values
        
        # Compute the Spearman's rank correlation coefficient and p-value
        corr, p_value = spearmanr(x, y)
        
        print(f'Spearman\'s rank correlation coefficient between {column_names[i]} and {column_names[j]}: {corr:.3f}')
        print(f'p-value: {p_value:.3f}')

"""# Descriptive statistics


"""

# Compute the descriptive statistics
stats = data.describe()

# Print the statistics
print(stats)

# Select specific columns from the dataframe
data = data[['CL=F','^GSPC', '^TNX', 'XOM']]

# Import numpy and train_test_split function from sklearn
import numpy as np
from sklearn.model_selection import train_test_split

# Split the data into a training and test set, with a 80/20 split
# test_size = 0.2 means 20% of the data will be used for testing
training_set, test_set = train_test_split(data, test_size=0.2)

# Convert the training and test sets to numpy arrays
training_set = training_set.values
test_set = test_set.values

# Check the shape of the test set
# The output will be the number of rows and columns in the test set
test_set.shape

# Import the StandardScaler class from the sklearn.preprocessing module
from sklearn.preprocessing import StandardScaler

# Create an instance of the StandardScaler class
sc = StandardScaler()

# Fit the StandardScaler to the training set and transform it
# This centers and scales the data so that the mean is 0 and the standard deviation is 1
training_set_scaled = sc.fit_transform(training_set)

# Apply the same scaling to the test set
test_set_scaled = sc.transform(test_set)

# Create the training set for the independent variables (X_train)
# This is all columns except the last column in the training set (scaled)
X_train = training_set_scaled[:,:-1]

# Create the training set for the dependent variable (y_train)
# This is the last column in the training set (scaled)
y_train = training_set_scaled[:,-1]

# Print the X_train and y_train to check the data
X_train, y_train

# Create the test set for the independent variables (X_test)
# This is all columns except the last column in the test set (scaled)
X_test = test_set_scaled[:,:-1]

# Create the test set for the dependent variable (y_test)
# This is the last column in the test set (scaled)
y_test = test_set_scaled[:,-1]

X_train.shape

"""MODEL.PY"""

from tensorflow import keras
import numpy as np
import tensorflow as tf

num_unique_vals = [
      len(np.unique(X_train[:, i])) for i in range(X_train.shape[-1])
  ]
num_units = [
      min(1000, i * 2) for i in num_unique_vals
  ]
num_inputs = X_train.shape[-1]

def create_nam_model(x_train,
                     dropout,
                     feature_dropout = 0.0,
                     num_basis_functions = 1000,
                     units_multiplier = 2,
                     activation = 'relu',
                     trainable = True):
  num_unique_vals = [
      len(np.unique(x_train[:, i])) for i in range(x_train.shape[-1])
  ]
  num_units = [
      min(num_basis_functions, i * units_multiplier) for i in num_unique_vals
  ]
  num_inputs = x_train.shape[-1]
  nn_model = NAM(
      x_train = x_train,
      num_inputs=num_inputs,
      num_units=num_units,
      feature_dropout= feature_dropout,
      dropout=np.float32(dropout),
      trainable=trainable)
  return nn_model


# Define the __init__ method that initializes the object instance.
# It takes the following arguments:
# - embed_dim: integer specifying the embedding dimension (default is 23)
# - num_heads: integer specifying the number of attention heads (default is 10)
# - ff_dim: integer specifying the size of the feedforward network (default is 10)
# - rate: float specifying the dropout rate (default is 0.1)
class TransformerBlock(tf.keras.layers.Layer):
    def __init__(self, embed_dim=23, num_heads=10, ff_dim=10, rate=0.1):
        super(TransformerBlock, self).__init__()
        self.att = tf.keras.layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)
        self.ffn = keras.Sequential(
            [tf.keras.layers.Dense(ff_dim, activation="elu"), tf.keras.layers.Dense(embed_dim),]
        )
        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)
        self.dropout1 = tf.keras.layers.Dropout(rate)
        self.dropout2 = tf.keras.layers.Dropout(rate)
        
# Define the call method to implement the forward pass of the layer.
# It takes the following arguments:
# - inputs: the input tensor
# - training: boolean flag indicating whether the layer is in training mode (default is True)
    def call(self, inputs, training=True):

        attn_output = self.att(inputs, inputs)
        attn_output = self.dropout1(attn_output, training=training)
        out1 = self.layernorm1(inputs + attn_output)
        ffn_output = self.ffn(out1)
        ffn_output = self.dropout2(ffn_output, training=training)
        return self.layernorm2(out1 + ffn_output)

class TokenAndPositionEmbedding(tf.keras.layers.Layer):
    def __init__(self, maxlen=200, seq_size=200, embed_dim=23):
        super(TokenAndPositionEmbedding, self).__init__()
        self.token_emb = tf.keras.layers.Embedding(input_dim=seq_size, output_dim=embed_dim)
        self.pos_emb = tf.keras.layers.Embedding(input_dim=maxlen, output_dim=embed_dim)

    def call(self, x):
        maxlen = tf.shape(x)[-1]
        positions = tf.range(start=0, limit=maxlen, delta=1)
        positions = self.pos_emb(positions)
        x = self.token_emb(x)
        return x + positions

class Transformer(tf.keras.Model):
    def __init__(self, input_dim, seq_len, output_dim=1):
        super(Transformer, self).__init__()
        self.input_dim = input_dim
        self.seq_len = seq_len
        self.output_dim = output_dim
        self.embedding_layer = TokenAndPositionEmbedding(seq_size=input_dim, maxlen=seq_len)
        self.transformer_block = TransformerBlock()
        self.gap1d = tf.keras.layers.GlobalAveragePooling1D()
        self.dropout = tf.keras.layers.Dropout(0.1)
        self.dense = tf.keras.layers.Dense(1)
        
    def call(self, inputs):
        x = self.embedding_layer(inputs)
        x = self.transformer_block(x)
        x = self.gap1d(x)
        x = self.dropout(x)
        outputs = self.dense(x)
        return outputs

class NAM(tf.keras.Model):
  def __init__(self,
               x_train,
               num_inputs,
               num_units,
               feature_dropout,
               dropout = 0.0,
               trainable = True,):
    super(NAM, self).__init__()
    self._num_inputs = num_inputs
    self._x_train = x_train
    self._feature_dropout = feature_dropout
    self._num_units = num_units
    self._dropout = dropout
    self._trainable = trainable
 
  def build(self, input_shape):
    self.transformers = [None] * self._num_inputs
    for i in range(self._num_inputs):
      self.transformers[i] = Transformer(input_dim=self._x_train.shape[-1], seq_len=self._x_train.shape[-2], output_dim=self._num_units)
    self._bias = self.add_weight(
        name='bias',
        initializer=tf.keras.initializers.Zeros(),
        trainable=True,)
    self._true = tf.constant(True, dtype=tf.bool)
    self._false = tf.constant(False, dtype=tf.bool)
 
  def call(self, x, training=True):
    individual_outputs = self.calc_outputs(x, training=training)
    stacked_out = tf.stack(individual_outputs, axis=-1)
    training = self._true if training else self._false
    dropout_out = tf.nn.dropout(
        stacked_out,
        rate=tf.cond(training, lambda: self._feature_dropout, lambda: 0.0))
    out = tf.reduce_sum(dropout_out, axis=-1)
    return out + self._bias

  def calc_outputs(self, x, training=True):
    list_x = tf.split(x, self._num_inputs, axis=-1)
    return [
        self.transformers[i](x_i)
        for i, x_i in enumerate(list_x)
    ]

  def score(self, x, y):
        # Compute model performance metric
        y_pred = self.predict(x)
        return np.mean(y_pred == y)  # Example metric: mean accuracy

tf.compat.v1.reset_default_graph()
TNAM = create_nam_model(
    x_train = X_train, 
    dropout = 0.2,)

_ = TNAM(X_train)
TNAM.summary()

# Compile the model
# The optimizer is the algorithm used to update the model's weights
# Adam is a popular choice for neural networks
# The loss function measures how well the model is doing, and the optimizer tries to minimize it
# MeanSquaredError is a common choice for regression problems
# The metrics is used to monitor the training and testing steps. It's useful to have an idea of how well the model is doing
TNAM.compile(optimizer=tf.keras.optimizers.Adam() , 
                    loss= tf.keras.losses.MeanSquaredError(),
                    metrics = tf.keras.metrics.RootMeanSquaredError(),)

TNAM.fit(X_train, y_train, epochs = 100, batch_size = 32)

# Evaluate the model on the test set
# This will return the loss and any metrics specified during model compilation
TNAM.evaluate(X_test,y_test)

# Use the model to make predictions on the test set
predicted_stock_price = TNAM.predict(X_test)
y_pred = predicted_stock_price

# Reshape y_test to have the same shape as the predictions
y_test = np.reshape(y_test, (759,1))

# Print the shape of y_test and the predictions to check they match
print("y_test.shape=",y_test.shape,
      "y_pred.shape=",predicted_stock_price.shape)

"""Uncomment to code below only if you want to plot the real and predicted values.Otherwise you will see the normalized real and normalized predicted values"""

# # Inverse scaling the training and test set
# training_set_original = sc.inverse_transform(training_set_scaled)
# test_set_original = sc.inverse_transform(test_set_scaled)

# # Extracting the independent and dependent variables for the training set
# # X_train contains all columns except the last column
# X_train = training_set_original[:,:-1]
# # y_train contains only the last column
# y_train = training_set_original[:,-1]

# # Extracting the independent and dependent variables for the test set
# # X_test contains all columns except the last column
# X_test = test_set_original[:,:-1]
# # y_test contains only the last column
# y_test = test_set_original[:,-1]

# # Inverse scaling the predicted stock price
# predicted_stock_price = y_pred*sc.scale_[-1]+sc.mean_[-1]

from sklearn import metrics as sk_metrics


def rmse(y_true, y_pred):
  """Root mean squared error between true and predicted values."""
  return float(np.sqrt(sk_metrics.mean_squared_error(y_true, y_pred)))

def mae(y_true, y_pred):
  """Mean Absolute Error between true and predicted values."""
  return float(sk_metrics.mean_absolute_error(y_true, y_pred)) 
def mse(y_true, y_pred):
  """Mean squared error between true and predicted values."""
  return float(sk_metrics.mean_squared_error(y_true, y_pred))

def r2_score(y_true, y_pred):
  """R-squared score between true and predicted values."""
  return float(sk_metrics.r2_score(y_true, y_pred)) 
  
def sigmoid(x):
  """Sigmoid function."""
  if isinstance(x, list):
    x = np.array(x)
  return np.where(x >= 0, 1 / (1 + np.exp(-x)), np.exp(x) / (1 + np.exp(x)))

def calculate_metric(y_true,
                     predictions,
                     regression = True):
  """Calculates the evaluation metric."""
  if regression:
    return mse(y_true, predictions)
  else:
    return sk_metrics.roc_auc_score(y_true, sigmoid(predictions))

# Call function that calculates a specific evaluation metric
test_metric = calculate_metric(y_test, predicted_stock_price, regression=True)

# Print the calculated metric
print(test_metric)

import matplotlib.pyplot as plt

# Set the size of the chart to 10x5 inches
plt.figure(figsize=(10, 5))
# Add a grid to the chart to improve readability
plt.grid(visible=True, linestyle='-.')
# Plot the real stock price in red and the predicted stock price in blue
plt.plot(y_test, color = 'red', label = 'Real Stock Price')
plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Stock Price')
# Set the title of the chart to 'TNAM Prediction' and increase the font size
plt.title('TΝΑΜ Prediction', fontsize=20)
# Set the x-axis label to 'Time' and increase the font size
plt.xlabel('Time', fontsize=15)
# Set the y-axis label to 'Stock Price' and increase the font size
plt.ylabel('Stock Price', fontsize=15)
# Add a legend to the chart and increase the font size
plt.legend(fontsize=15)
# Set the y-axis limits to the minimum and maximum stock prices with an additional 10% buffer on either side
plt.ylim(bottom=min(y_test) - (max(y_test) - min(y_test))*0.1, top=max(y_test) + (max(y_test) - min(y_test))*0.1)
# Save the chart as an image file named 'TNAM.png' 
# plt.savefig("TNAM.png")

plt.show()

import numpy as np
from sklearn.metrics import r2_score

y_pred = predicted_stock_price

# Calculate the baseline performance
baseline_r2 = r2_score(y_test, y_pred)

# Initialize a list to store the feature importance scores
permutation_scores = []

# Iterate over each feature
for feature in range(X_train.shape[1]):
    # Shuffle the values of the current feature
    X_train_shuffled = X_train.copy()
    X_train_shuffled[:, feature] = np.random.permutation(X_train[:, feature])

    # Re-fit the model and make predictions
    TNAM.fit(X_train_shuffled, y_train)
    y_pred_shuffled = TNAM.predict(X_test)

    # Calculate the decrease in performance
    r2 = r2_score(y_test, y_pred_shuffled)
    permutation_score = baseline_r2 - r2
    permutation_scores.append(permutation_score)

# normalize the feature importance to sum to 1
permutation_scores = np.array(permutation_scores)
permutation_scores /= permutation_scores.sum()

import matplotlib.pyplot as plt

# Create a bar chart to visualize the feature importance scores
plt.bar(range(X_train.shape[1]), permutation_scores, color='#00BFFF', edgecolor='#00008B')
# Set the x-axis ticks to the names of the dataset features and rotate them for better readability
plt.xticks(range(X_train.shape[1]), data.columns, rotation=45, fontsize=12)
# Set the title of the chart to 'Feature Importance TNAM' and increase the font size
plt.title('Feature Importance TNAM', fontsize=20)
# Set the y-axis label to 'Feature Importance Score' and increase the font size
plt.ylabel('Feature Importance Score', fontsize=14)
# Set the y-axis limits to 0 and the maximum feature importance score plus 0.1
plt.ylim(0, max(permutation_scores)+0.1)
# Add a grid to the chart to improve readability and save the chart as an image file
plt.grid(visible=True, linestyle='--', color='#D3D3D3')
plt.savefig('feature_importance TNAM.png', bbox_inches='tight')

plt.show()

!pip install shap

import shap
import matplotlib.pyplot as plt

# Create an explainer object to calculate the SHAP values
explainer = shap.Explainer(TNAM, X_test)
shap_values = explainer(X_test)

# Set the plot style to a more visually appealing style
plt.style.use('seaborn-darkgrid')

# Set the plot title
plt.title('SHAP Feature Importance Plot TNAM', fontsize=20)

# Create the bar plot of the feature importances
shap.summary_plot(shap_values, X_test, feature_names=['CL=F','^GSPC', '^TNX'], plot_type='bar')