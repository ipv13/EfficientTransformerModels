# -*- coding: utf-8 -*-
"""NAM.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QWhJv6eu8svuyoa10eCcTl8N1k6rDPXR
"""

# !pip install yfinance
# !pip3 install -U --verbose -e "git+https://github.com/agarwl/google-research.git#egg=neural_additive_models&subdirectory=neural_additive_models" # install a python package from a repo subdirectory
# exit()

"""## Importing data"""

# This code installs the yfinance library, which allows you to access financial data from Yahoo Finance
# !pip install yfinance

# Import the yfinance library and assign it to the alias 'yf'
import yfinance as yf

# Create a list of tickers for the stocks you want to retrieve data for
list_tickers = ['CL=F','^GSPC', '^TNX', 'XOM']

# Use the Tickers() function from yfinance to create an object for each ticker in the list
tickers = yf.Tickers(list_tickers)

# Use the download() function from yfinance to download the stock data for the specified date range
data = yf.download(list_tickers,  start="2007-06-01", end="2022-07-01")

# Extract the 'Close' column from the dataframe
data = data['Close']

# Print the dataframe
data

# Remove all rows with missing values (NaN) from the dataframe
data = data.dropna()

# Check if the dataframe still contains any missing values
# returns False if there is no missing values
data.isnull().values.any()

"""##Statistical analysis """

## Compute the Pearson's correlation coefficient between the columns
corr_matrix = data.corr()
print(corr_matrix)

## The spearmanr function returns two values: the Spearman's rank correlation coefficient (corr) and the p-value. The p-value can be used 
## to assess the statistical significance of the correlation. A small p-value (typically less than 0.05) 
## indicates that the correlation is statistically significant, while a large p-value suggests that the correlation may not be meaningful.

from scipy.stats import spearmanr

# Compute the Spearman's rank correlation matrix
corr_matrix = data.corr(method='spearman')

# Extract the column names
column_names = data.columns

# Loop through all pairs of variables
for i in range(len(column_names)):
    for j in range(i+1, len(column_names)):
        # Extract the columns of interest
        x = data[column_names[i]].values
        y = data[column_names[j]].values
        
        # Compute the Spearman's rank correlation coefficient and p-value
        corr, p_value = spearmanr(x, y)
        
        print(f'Spearman\'s rank correlation coefficient between {column_names[i]} and {column_names[j]}: {corr:.3f}')
        print(f'p-value: {p_value:.3f}')

"""# Descriptive statistics


"""

# Compute the descriptive statistics
stats = data.describe()

# Print the statistics
print(stats)

# Select specific columns from the dataframe
data = data[['CL=F','^GSPC', '^TNX', 'XOM']]

# Import numpy and train_test_split function from sklearn
import numpy as np
from sklearn.model_selection import train_test_split

# Split the data into a training and test set, with a 80/20 split
# test_size = 0.2 means 20% of the data will be used for testing
training_set, test_set = train_test_split(data, test_size=0.2)

# Convert the training and test sets to numpy arrays
training_set = training_set.values
test_set = test_set.values

# Check the shape of the test set
# The output will be the number of rows and columns in the test set
test_set.shape

# Import the StandardScaler class from the sklearn.preprocessing module
from sklearn.preprocessing import StandardScaler

# Create an instance of the StandardScaler class
sc = StandardScaler()

# Fit the StandardScaler to the training set and transform it
# This centers and scales the data so that the mean is 0 and the standard deviation is 1
training_set_scaled = sc.fit_transform(training_set)

# Apply the same scaling to the test set
test_set_scaled = sc.transform(test_set)

# Create the training set for the independent variables (X_train)
# This is all columns except the last column in the training set (scaled)
X_train = training_set_scaled[:,:-1]

# Create the training set for the dependent variable (y_train)
# This is the last column in the training set (scaled)
y_train = training_set_scaled[:,-1]

# Print the X_train and y_train to check the data
X_train, y_train

# Create the test set for the independent variables (X_test)
# This is all columns except the last column in the test set (scaled)
X_test = test_set_scaled[:,:-1]

# Create the test set for the dependent variable (y_test)
# This is the last column in the test set (scaled)
y_test = test_set_scaled[:,-1]

X_train.shape

"""MODEL.PY"""

#@title Imports

import tensorflow.compat.v2 as tf
tf.enable_v2_behavior()

import data_utils
import models as nam_models
import graph_builder
import os.path as osp
import numpy as np

import matplotlib.pyplot as plt

tf.compat.v1.reset_default_graph()
nn_model = graph_builder.create_nam_model(
    x_train=X_train,
    dropout=0.0,
    num_basis_functions=64,
    activation='relu',
    trainable=True,
    shallow=False,
    name_scope='model')

_ = nn_model(X_train[:1])
nn_model.summary()

# Compile the model
# The optimizer is the algorithm used to update the model's weights
# Adam is a popular choice for neural networks
# The loss function measures how well the model is doing, and the optimizer tries to minimize it
# MeanSquaredError is a common choice for regression problems
# The metrics is used to monitor the training and testing steps. It's useful to have an idea of how well the model is doing
nn_model.compile(optimizer=tf.keras.optimizers.Adam(), 
                    loss= tf.keras.losses.MeanSquaredError(),
                    metrics = tf.keras.metrics.RootMeanSquaredError(),)

nn_model.fit(X_train, y_train, epochs = 100, batch_size = 32)

# Evaluate the model on the test set
# This will return the loss and any metrics specified during model compilation
nn_model.evaluate(X_test,y_test)

# Use the model to make predictions on the test set
predicted_stock_price = nn_model.predict(X_test)
y_pred = predicted_stock_price
# Reshape y_test to have the same shape as the predictions
y_test = np.reshape(y_test, (759,1))

# Print the shape of y_test and the predictions to check they match
print("y_test.shape=",y_test.shape,
      "y_pred.shape=",predicted_stock_price.shape)

# # Inverse scaling the training and test set
# training_set_original = sc.inverse_transform(training_set_scaled)
# test_set_original = sc.inverse_transform(test_set_scaled)

# # Extracting the independent and dependent variables for the training set
# # X_train contains all columns except the last column
# X_train = training_set_original[:,:-1]
# # y_train contains only the last column
# y_train = training_set_original[:,-1]

# # Extracting the independent and dependent variables for the test set
# # X_test contains all columns except the last column
# X_test = test_set_original[:,:-1]
# # y_test contains only the last column
# y_test = test_set_original[:,-1]

# # Inverse scaling the predicted stock price
# predicted_stock_price = y_pred*sc.scale_[-1]+sc.mean_[-1]

from sklearn import metrics as sk_metrics

def rmse(y_true, y_pred):
  """Root mean squared error between true and predicted values."""
  return float(np.sqrt(sk_metrics.mean_squared_error(y_true, y_pred)))

def mae(y_true, y_pred):
  """Mean Absolute Error between true and predicted values."""
  return float(sk_metrics.mean_absolute_error(y_true, y_pred)) 

def mse(y_true, y_pred):
  """Mean squared error between true and predicted values."""
  return float(sk_metrics.mean_squared_error(y_true, y_pred))

def r2_score(y_true, y_pred):
  """R-squared score between true and predicted values."""
  return float(sk_metrics.r2_score(y_true, y_pred)) 

def sigmoid(x):
  """Sigmoid function."""
  if isinstance(x, list):
    x = np.array(x)
  return np.where(x >= 0, 1 / (1 + np.exp(-x)), np.exp(x) / (1 + np.exp(x)))

def calculate_metric(y_true,
                     predictions,
                     regression = True):
  """Calculates the evaluation metric."""
  if regression:
    return r2_score(y_true, predictions)
  else:
    return sk_metrics.roc_auc_score(y_true, sigmoid(predictions))

# Call function that calculates a specific evaluation metric
test_metric = calculate_metric(y_test, predicted_stock_price, regression=True)

# Print the calculated metric
print(test_metric)

import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.grid(visible=True, linestyle='-.')
plt.plot(y_test, color = 'red', label = 'Real Stock Price')
plt.plot(predicted_stock_price, color = 'blue', label = 'Predicted Stock Price')
plt.title('ΝΑΜ Prediction', fontsize=20)
plt.xlabel('Time', fontsize=15)
plt.ylabel('Stock Price', fontsize=15)
plt.legend(fontsize=15)
plt.ylim(bottom=min(y_test) - (max(y_test) - min(y_test))*0.1, top=max(y_test) + (max(y_test) - min(y_test))*0.1)
plt.savefig("NAM.png")

plt.show()

import numpy as np
from sklearn.metrics import r2_score

y_pred = predicted_stock_price

# Calculate the baseline performance
baseline_r2 = r2_score(y_test, y_pred)

# Initialize a list to store the feature importance scores
permutation_scores = []

# Iterate over each feature
for feature in range(X_train.shape[1]):
    # Shuffle the values of the current feature
    X_train_shuffled = X_train.copy()
    X_train_shuffled[:, feature] = np.random.permutation(X_train[:, feature])

    # Re-fit the model and make predictions
    nn_model.fit(X_train_shuffled, y_train)
    y_pred_shuffled = nn_model.predict(X_test)

    # Calculate the decrease in performance
    r2 = r2_score(y_test, y_pred_shuffled)
    permutation_score = baseline_r2 - r2
    permutation_scores.append(permutation_score)

# normalize the feature importance to sum to 1
permutation_scores = np.array(permutation_scores)
permutation_scores /= permutation_scores.sum()

import matplotlib.pyplot as plt

plt.bar(range(X_train.shape[1]), permutation_scores, color='#00BFFF', edgecolor='#00008B')
plt.xticks(range(X_train.shape[1]), data.columns, rotation=45, fontsize=12)
plt.title('Feature Importance NAM', fontsize=20)
plt.ylabel('Feature Importance Score', fontsize=14)
plt.ylim(0, max(permutation_scores)+0.1)
plt.grid(visible=True, linestyle='--', color='#D3D3D3')
plt.savefig('feature_importance NAM.png', bbox_inches='tight')

plt.show()

from sklearn.inspection import permutation_importance
from sklearn.metrics import mean_squared_error

# Make predictions on the test data
y_pred = predicted_stock_price

# Calculate the feature importance scores
result = permutation_importance(nn_model, X_test, y_pred, scoring = "neg_mean_squared_error")

# to get the feature importance
feature_importance = result.importances_mean

import matplotlib.pyplot as plt


plt.bar(range(len(feature_importance)), feature_importance, color='#00BFFF', edgecolor='#00008B')
plt.xticks(range(len(feature_importance)), data.columns, rotation=45, fontsize=12)
plt.title('Feature Importance Scores', fontsize=20)
plt.ylabel('Feature Importance Score', fontsize=14)
plt.ylim(0, max(feature_importance)+10)
plt.grid(visible=True, linestyle='--', color='#D3D3D3')

plt.show()

!pip install shap

import shap
import matplotlib.pyplot as plt

# Create an explainer object to calculate the SHAP values
explainer = shap.Explainer(nn_model, X_test)
shap_values = explainer(X_test)

# Set the plot style to a more visually appealing style
plt.style.use('seaborn-darkgrid')

# Set the plot title
plt.title('SHAP Feature Importance Plot NAM', fontsize=20)

# Create the bar plot of the feature importances
shap.summary_plot(shap_values, X_test, feature_names=['CL=F','^GSPC', '^TNX'], plot_type='bar')

# # Save the figure to an HTML file
# shap.save_html("SHAP Feature Importance Plot NAM.png", plot = shap.force_plot(shap_values, X_test, feature_names=['CL=F','^GSPC', '^TNX']))